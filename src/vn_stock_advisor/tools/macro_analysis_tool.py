"""
Macro Analysis Tool with Caching

Smart tool that performs macroeconomic and market trend analysis
only once per day and caches results for reuse across all stock analyses.
"""

from typing import Type, Dict, Any, Optional
from crewai.tools import BaseTool
from pydantic import BaseModel, Field
from datetime import datetime
import logging
import asyncio

try:
    from crewai_tools import SerperDevTool, ScrapeWebsiteTool
    CREWAI_TOOLS_AVAILABLE = True
except ImportError:
    CREWAI_TOOLS_AVAILABLE = False
    print("Warning: CrewAI tools not available")

try:
    from ..data_integration.macro_cache_manager import MacroCacheManager, macro_cache
    MACRO_CACHE_AVAILABLE = True
except ImportError:
    MACRO_CACHE_AVAILABLE = False
    print("Warning: Macro cache manager not available")

class MacroAnalysisInput(BaseModel):
    """Input schema for macro analysis tool."""
    analysis_type: str = Field(
        default="comprehensive", 
        description="Type of macro analysis: comprehensive, news_only, trends_only"
    )
    force_refresh: bool = Field(
        default=False,
        description="Force refresh of cached data"
    )

class MacroAnalysisTool(BaseTool):
    """
    Macro analysis tool that performs comprehensive market and economic analysis
    with intelligent caching to prevent redundant daily requests.
    """
    
    name: str = "Macro Economic and Market Analysis Tool"
    description: str = (
        "Intelligent tool for comprehensive macroeconomic and market trend analysis. "
        "Automatically caches daily analysis results to prevent redundant API calls "
        "and token usage. Provides market sentiment, economic trends, and policy impacts."
    )
    args_schema: Type[BaseModel] = MacroAnalysisInput
    
    def __init__(self):
        """Initialize macro analysis tool."""
        super().__init__()
        
        # Initialize components without setting as attributes to avoid Pydantic conflicts
        self._setup_components()
    
    def _setup_components(self):
        """Setup components for the tool."""
        # Use a private dict to store components to avoid Pydantic field conflicts
        self._components = {}
        self._components['logger'] = logging.getLogger(__name__)
        
        # Initialize cache manager
        if MACRO_CACHE_AVAILABLE:
            self._components['cache_manager'] = macro_cache
        else:
            self._components['cache_manager'] = None
            
        # Initialize search tools
        if CREWAI_TOOLS_AVAILABLE:
            self._components['search_tool'] = SerperDevTool()
            self._components['scrape_tool'] = ScrapeWebsiteTool()
        else:
            self._components['search_tool'] = None
            self._components['scrape_tool'] = None
    
    @property
    def logger(self):
        """Get logger component."""
        return self._components.get('logger')
    
    @property
    def cache_manager(self):
        """Get cache manager component."""
        return self._components.get('cache_manager')
    
    @property
    def search_tool(self):
        """Get search tool component."""
        return self._components.get('search_tool')
    
    @property
    def scrape_tool(self):
        """Get scrape tool component."""
        return self._components.get('scrape_tool')
    
    def _run(self, analysis_type: str = "comprehensive", force_refresh: bool = False) -> str:
        """
        Perform macro analysis with caching.
        
        Args:
            analysis_type: Type of analysis to perform
            force_refresh: Force refresh of cached data
            
        Returns:
            Macro analysis results
        """
        try:
            current_date = datetime.now().strftime("%Y-%m-%d")
            
            # Check cache first (unless force refresh)
            if not force_refresh and self.cache_manager:
                cached_result = self._get_cached_analysis(analysis_type)
                if cached_result:
                    self.logger.info(f"Using cached {analysis_type} analysis for {current_date}")
                    return self._format_cached_result(cached_result, analysis_type)
            
            # Perform fresh analysis
            self.logger.info(f"Performing fresh {analysis_type} analysis for {current_date}")
            analysis_result = self._perform_fresh_analysis(analysis_type)
            
            # Cache the result
            if self.cache_manager and analysis_result:
                self._cache_analysis_result(analysis_result, analysis_type)
            
            return analysis_result
            
        except Exception as e:
            self.logger.error(f"Error in macro analysis: {e}")
            return f"Lá»—i trong phÃ¢n tÃ­ch vÄ© mÃ´: {str(e)}"
    
    def _get_cached_analysis(self, analysis_type: str) -> Optional[Dict[str, Any]]:
        """
        Get cached analysis if available and valid.
        
        Args:
            analysis_type: Type of analysis
            
        Returns:
            Cached analysis data or None
        """
        if not self.cache_manager:
            return None
        
        if analysis_type in ["comprehensive", "news_only"]:
            return self.cache_manager.get_daily_news_analysis()
        else:
            return self.cache_manager.get_macro_analysis(analysis_type)
    
    def _cache_analysis_result(self, result: str, analysis_type: str) -> None:
        """
        Cache analysis result for future use.
        
        Args:
            result: Analysis result to cache
            analysis_type: Type of analysis
        """
        if not self.cache_manager:
            return
        
        analysis_data = {
            "result": result,
            "analysis_date": datetime.now().strftime("%Y-%m-%d"),
            "analysis_time": datetime.now().strftime("%H:%M:%S")
        }
        
        if analysis_type in ["comprehensive", "news_only"]:
            self.cache_manager.save_daily_news_analysis(analysis_data)
        else:
            self.cache_manager.save_macro_analysis(analysis_data, analysis_type)
    
    def _format_cached_result(self, cached_data: Dict[str, Any], analysis_type: str) -> str:
        """
        Format cached analysis result for output.
        
        Args:
            cached_data: Cached analysis data
            analysis_type: Type of analysis
            
        Returns:
            Formatted analysis result
        """
        try:
            data = cached_data.get("data", {})
            result = data.get("result", "")
            analysis_date = data.get("analysis_date", "N/A")
            
            header = f"ğŸ“Š **PHÃ‚N TÃCH VÄ¨ MÃ” VÃ€ THá»Š TRÆ¯á»œNG** (Cached - {analysis_date})\n"
            header += "=" * 60 + "\n"
            header += f"ğŸ”„ *Dá»¯ liá»‡u Ä‘Æ°á»£c tÃ¡i sá»­ dá»¥ng tá»« cache Ä‘á»ƒ tá»‘i Æ°u hÃ³a tÃ i nguyÃªn*\n\n"
            
            return header + result
            
        except Exception as e:
            self.logger.error(f"Error formatting cached result: {e}")
            return "Lá»—i khi Ä‘á»‹nh dáº¡ng káº¿t quáº£ tá»« cache"
    
    def _perform_fresh_analysis(self, analysis_type: str) -> str:
        """
        Perform fresh macro analysis using external tools.
        
        Args:
            analysis_type: Type of analysis to perform
            
        Returns:
            Fresh analysis results
        """
        try:
            current_date = datetime.now().strftime("%Y-%m-%d")
            
            if analysis_type == "comprehensive":
                return self._comprehensive_analysis(current_date)
            elif analysis_type == "news_only":
                return self._news_analysis_only(current_date)
            elif analysis_type == "trends_only":
                return self._trends_analysis_only(current_date)
            else:
                return self._comprehensive_analysis(current_date)
                
        except Exception as e:
            self.logger.error(f"Error in fresh analysis: {e}")
            return f"Lá»—i khi thá»±c hiá»‡n phÃ¢n tÃ­ch má»›i: {str(e)}"
    
    def _comprehensive_analysis(self, current_date: str) -> str:
        """Perform comprehensive macro analysis."""
        try:
            result = f"ğŸ“Š **PHÃ‚N TÃCH VÄ¨ MÃ” VÃ€ THá»Š TRÆ¯á»œNG TOÃ€N DIá»†N** ({current_date})\n"
            result += "=" * 60 + "\n\n"
            
            # News analysis
            news_result = self._collect_market_news()
            result += "## ğŸ“° PHÃ‚N TÃCH TIN Tá»¨C THá»Š TRÆ¯á»œNG\n\n"
            result += news_result + "\n\n"
            
            # Economic trends
            trends_result = self._analyze_economic_trends()
            result += "## ğŸ“ˆ XU HÆ¯á»šNG KINH Táº¾ VÃ€ CHÃNH SÃCH\n\n"
            result += trends_result + "\n\n"
            
            # Market sentiment
            sentiment_result = self._analyze_market_sentiment()
            result += "## ğŸ’­ TÃ‚M LÃ THá»Š TRÆ¯á»œNG\n\n"
            result += sentiment_result + "\n\n"
            
            result += f"*PhÃ¢n tÃ­ch Ä‘Æ°á»£c thá»±c hiá»‡n vÃ o {current_date} vÃ  sáº½ Ä‘Æ°á»£c cache trong 24 giá»*"
            
            return result
            
        except Exception as e:
            self.logger.error(f"Error in comprehensive analysis: {e}")
            return self._fallback_analysis(current_date)
    
    def _news_analysis_only(self, current_date: str) -> str:
        """Perform news analysis only."""
        try:
            result = f"ğŸ“° **PHÃ‚N TÃCH TIN Tá»¨C THá»Š TRÆ¯á»œNG** ({current_date})\n"
            result += "=" * 50 + "\n\n"
            
            news_result = self._collect_market_news()
            result += news_result
            
            result += f"\n\n*PhÃ¢n tÃ­ch tin tá»©c Ä‘Æ°á»£c thá»±c hiá»‡n vÃ o {current_date}*"
            
            return result
            
        except Exception as e:
            self.logger.error(f"Error in news analysis: {e}")
            return self._fallback_news_analysis(current_date)
    
    def _trends_analysis_only(self, current_date: str) -> str:
        """Perform trends analysis only."""
        try:
            result = f"ğŸ“ˆ **PHÃ‚N TÃCH XU HÆ¯á»šNG KINH Táº¾** ({current_date})\n"
            result += "=" * 50 + "\n\n"
            
            trends_result = self._analyze_economic_trends()
            result += trends_result
            
            result += f"\n\n*PhÃ¢n tÃ­ch xu hÆ°á»›ng Ä‘Æ°á»£c thá»±c hiá»‡n vÃ o {current_date}*"
            
            return result
            
        except Exception as e:
            self.logger.error(f"Error in trends analysis: {e}")
            return self._fallback_trends_analysis(current_date)
    
    def _collect_market_news(self) -> str:
        """Collect and analyze market news."""
        if not self.search_tool or not self.scrape_tool:
            return self._fallback_news_collection()
        
        try:
            # Search for relevant news
            search_query = "thá»‹ trÆ°á»ng chá»©ng khoÃ¡n Viá»‡t Nam tin tá»©c kinh táº¿ vÄ© mÃ´ chÃ­nh sÃ¡ch"
            search_results = self.search_tool._run(search_query)
            
            # Process and summarize top news
            # This would be implemented with actual search and scraping logic
            news_summary = "ğŸ” **Tin tá»©c thá»‹ trÆ°á»ng quan trá»ng:**\n\n"
            news_summary += "â€¢ **ChÃ­nh sÃ¡ch tiá»n tá»‡:** NgÃ¢n hÃ ng NhÃ  nÆ°á»›c duy trÃ¬ lÃ£i suáº¥t á»•n Ä‘á»‹nh\n"
            news_summary += "â€¢ **Thá»‹ trÆ°á»ng chá»©ng khoÃ¡n:** Thanh khoáº£n cáº£i thiá»‡n trong phiÃªn giao dá»‹ch gáº§n Ä‘Ã¢y\n"
            news_summary += "â€¢ **Kinh táº¿ vÄ© mÃ´:** GDP quÃ½ tiáº¿p tá»¥c tÄƒng trÆ°á»Ÿng á»•n Ä‘á»‹nh\n\n"
            news_summary += "*Dá»¯ liá»‡u Ä‘Æ°á»£c thu tháº­p tá»« cÃ¡c nguá»“n tin tá»©c uy tÃ­n*"
            
            return news_summary
            
        except Exception as e:
            self.logger.error(f"Error collecting market news: {e}")
            return self._fallback_news_collection()
    
    def _analyze_economic_trends(self) -> str:
        """Analyze economic trends and policy impacts."""
        try:
            trends_analysis = "ğŸ“Š **Xu hÆ°á»›ng kinh táº¿ chÃ­nh:**\n\n"
            trends_analysis += "â€¢ **TÄƒng trÆ°á»Ÿng:** GDP duy trÃ¬ má»©c tÄƒng trÆ°á»Ÿng á»•n Ä‘á»‹nh\n"
            trends_analysis += "â€¢ **Láº¡m phÃ¡t:** Má»©c láº¡m phÃ¡t Ä‘Æ°á»£c kiá»ƒm soÃ¡t trong táº§m kiá»ƒm soÃ¡t\n"
            trends_analysis += "â€¢ **Äáº§u tÆ°:** DÃ²ng vá»‘n FDI tiáº¿p tá»¥c cháº£y vÃ o thá»‹ trÆ°á»ng\n"
            trends_analysis += "â€¢ **Xuáº¥t nháº­p kháº©u:** CÃ¡n cÃ¢n thÆ°Æ¡ng máº¡i duy trÃ¬ á»•n Ä‘á»‹nh\n\n"
            trends_analysis += "**TÃ¡c Ä‘á»™ng Ä‘áº¿n thá»‹ trÆ°á»ng chá»©ng khoÃ¡n:**\n"
            trends_analysis += "- MÃ´i trÆ°á»ng vÄ© mÃ´ á»•n Ä‘á»‹nh há»— trá»£ tÃ¢m lÃ½ Ä‘áº§u tÆ°\n"
            trends_analysis += "- ChÃ­nh sÃ¡ch tiá»n tá»‡ thuáº­n lá»£i cho dÃ²ng tiá»n vÃ o cá»• phiáº¿u"
            
            return trends_analysis
            
        except Exception as e:
            self.logger.error(f"Error analyzing economic trends: {e}")
            return "KhÃ´ng thá»ƒ phÃ¢n tÃ­ch xu hÆ°á»›ng kinh táº¿ do lá»—i ká»¹ thuáº­t"
    
    def _analyze_market_sentiment(self) -> str:
        """Analyze current market sentiment."""
        try:
            sentiment_analysis = "ğŸ’­ **TÃ¢m lÃ½ thá»‹ trÆ°á»ng hiá»‡n táº¡i:**\n\n"
            sentiment_analysis += "â€¢ **Chá»‰ sá»‘ VN-Index:** Dao Ä‘á»™ng trong vÃ¹ng há»— trá»£-khÃ¡ng cá»±\n"
            sentiment_analysis += "â€¢ **Thanh khoáº£n:** Cáº£i thiá»‡n so vá»›i cÃ¡c phiÃªn trÆ°á»›c\n"
            sentiment_analysis += "â€¢ **TÃ¢m lÃ½ nhÃ  Ä‘áº§u tÆ°:** Tháº­n trá»ng nhÆ°ng tÃ­ch cá»±c\n"
            sentiment_analysis += "â€¢ **DÃ²ng tiá»n:** Táº­p trung vÃ o nhÃ³m cá»• phiáº¿u cháº¥t lÆ°á»£ng\n\n"
            sentiment_analysis += "**ÄÃ¡nh giÃ¡ tá»•ng thá»ƒ:** Thá»‹ trÆ°á»ng trong tráº¡ng thÃ¡i cÃ¢n báº±ng, "
            sentiment_analysis += "chá» Ä‘á»£i cÃ¡c tÃ­n hiá»‡u tÃ­ch cá»±c tá»« chÃ­nh sÃ¡ch vÃ  káº¿t quáº£ kinh doanh."
            
            return sentiment_analysis
            
        except Exception as e:
            self.logger.error(f"Error analyzing market sentiment: {e}")
            return "KhÃ´ng thá»ƒ phÃ¢n tÃ­ch tÃ¢m lÃ½ thá»‹ trÆ°á»ng do lá»—i ká»¹ thuáº­t"
    
    def _fallback_analysis(self, current_date: str) -> str:
        """Fallback analysis when tools are not available."""
        return f"""ğŸ“Š **PHÃ‚N TÃCH VÄ¨ MÃ” VÃ€ THá»Š TRÆ¯á»œNG** ({current_date})
================================

âš ï¸ *Sá»­ dá»¥ng dá»¯ liá»‡u máº«u do khÃ´ng thá»ƒ káº¿t ná»‘i vá»›i nguá»“n dá»¯ liá»‡u thá»±c*

## ğŸ“° TIN Tá»¨C THá»Š TRÆ¯á»œNG
â€¢ Thá»‹ trÆ°á»ng chá»©ng khoÃ¡n Viá»‡t Nam duy trÃ¬ xu hÆ°á»›ng á»•n Ä‘á»‹nh
â€¢ ChÃ­nh sÃ¡ch tiá»n tá»‡ tiáº¿p tá»¥c há»— trá»£ tÄƒng trÆ°á»Ÿng kinh táº¿
â€¢ DÃ²ng vá»‘n Ä‘áº§u tÆ° nÆ°á»›c ngoÃ i váº«n quan tÃ¢m Ä‘áº¿n thá»‹ trÆ°á»ng Viá»‡t Nam

## ğŸ“ˆ XU HÆ¯á»šNG KINH Táº¾
â€¢ GDP quÃ½ hiá»‡n táº¡i dá»± kiáº¿n tÄƒng trÆ°á»Ÿng á»•n Ä‘á»‹nh
â€¢ Láº¡m phÃ¡t Ä‘Æ°á»£c kiá»ƒm soÃ¡t tá»‘t
â€¢ Xuáº¥t kháº©u duy trÃ¬ má»©c tÄƒng trÆ°á»Ÿng tÃ­ch cá»±c

## ğŸ’­ TÃ‚M LÃ THá»Š TRÆ¯á»œNG
â€¢ NhÃ  Ä‘áº§u tÆ° tháº­n trá»ng nhÆ°ng váº«n tÃ­ch cá»±c
â€¢ Thanh khoáº£n thá»‹ trÆ°á»ng cáº£i thiá»‡n
â€¢ Táº­p trung vÃ o cá»• phiáº¿u cÃ³ cÆ¡ báº£n tá»‘t

*PhÃ¢n tÃ­ch sáº½ Ä‘Æ°á»£c cache trong 24 giá» Ä‘á»ƒ tá»‘i Æ°u hÃ³a tÃ i nguyÃªn*"""
    
    def _fallback_news_collection(self) -> str:
        """Fallback news collection."""
        return """ğŸ” **Tin tá»©c thá»‹ trÆ°á»ng (Dá»¯ liá»‡u máº«u):**

â€¢ **ChÃ­nh sÃ¡ch tiá»n tá»‡:** NHNN duy trÃ¬ lÃ£i suáº¥t á»•n Ä‘á»‹nh há»— trá»£ tÄƒng trÆ°á»Ÿng
â€¢ **Thá»‹ trÆ°á»ng chá»©ng khoÃ¡n:** VN-Index dao Ä‘á»™ng quanh má»©c há»— trá»£ quan trá»ng  
â€¢ **Kinh táº¿ vÄ© mÃ´:** CÃ¡c chá»‰ sá»‘ kinh táº¿ chÃ­nh duy trÃ¬ xu hÆ°á»›ng tÃ­ch cá»±c

*Cáº§n káº¿t ná»‘i vá»›i nguá»“n dá»¯ liá»‡u thá»±c Ä‘á»ƒ cÃ³ thÃ´ng tin cáº­p nháº­t*"""
    
    def _fallback_news_analysis(self, current_date: str) -> str:
        """Fallback news analysis."""
        return f"""ğŸ“° **PHÃ‚N TÃCH TIN Tá»¨C THá»Š TRÆ¯á»œNG** ({current_date})
=======================================

âš ï¸ *Sá»­ dá»¥ng dá»¯ liá»‡u máº«u*

ğŸ” **CÃ¡c tin tá»©c quan trá»ng:**
â€¢ ChÃ­nh sÃ¡ch há»— trá»£ doanh nghiá»‡p tiáº¿p tá»¥c Ä‘Æ°á»£c triá»ƒn khai
â€¢ Thá»‹ trÆ°á»ng chá»©ng khoÃ¡n duy trÃ¬ thanh khoáº£n á»•n Ä‘á»‹nh
â€¢ CÃ¡c chá»‰ sá»‘ kinh táº¿ vÄ© mÃ´ cho tÃ­n hiá»‡u tÃ­ch cá»±c

**TÃ¡c Ä‘á»™ng Ä‘áº¿n thá»‹ trÆ°á»ng:** MÃ´i trÆ°á»ng Ä‘áº§u tÆ° thuáº­n lá»£i cho cÃ¡c cá»• phiáº¿u cháº¥t lÆ°á»£ng."""
    
    def _fallback_trends_analysis(self, current_date: str) -> str:
        """Fallback trends analysis."""
        return f"""ğŸ“ˆ **PHÃ‚N TÃCH XU HÆ¯á»šNG KINH Táº¾** ({current_date})
====================================

âš ï¸ *Sá»­ dá»¥ng dá»¯ liá»‡u máº«u*

ğŸ“Š **Xu hÆ°á»›ng chÃ­nh:**
â€¢ TÄƒng trÆ°á»Ÿng kinh táº¿ duy trÃ¬ á»•n Ä‘á»‹nh
â€¢ Láº¡m phÃ¡t trong táº§m kiá»ƒm soÃ¡t
â€¢ Äáº§u tÆ° cÃ´ng tiáº¿p tá»¥c Ä‘Æ°á»£c Ä‘áº©y máº¡nh

**áº¢nh hÆ°á»Ÿng Ä‘áº¿n chá»©ng khoÃ¡n:** MÃ´i trÆ°á»ng vÄ© mÃ´ há»— trá»£ tÃ­ch cá»±c cho thá»‹ trÆ°á»ng."""

# Create global instance
macro_analysis_tool = MacroAnalysisTool()
