from typing import Type, Optional, Any
from crewai.tools import BaseTool
from pydantic import BaseModel, Field
from vnstock import Vnstock
from datetime import datetime, timedelta
import pandas as pd
import numpy as np

try:
    import talib as ta
    TA_AVAILABLE = True
except ImportError:
    TA_AVAILABLE = False
    print("Warning: TA-Lib not available. Some technical indicators may not work.")

# Import ML and Technical Analysis modules
try:
    from ..ml.pattern_recognition import PatternRecognition
    from ..ml.anomaly_detection import AnomalyDetection
    from ..ml.sentiment_analyzer import SentimentAnalyzer
    from ..technical.fibonacci_calculator import FibonacciCalculator
    from ..technical.ichimoku_analyzer import IchimokuAnalyzer
    from ..technical.volume_analyzer import VolumeAnalyzer
    from ..technical.divergence_detector import DivergenceDetector
except ImportError as e:
    print(f"Warning: Could not import ML/Technical modules: {e}")
    PatternRecognition = None
    AnomalyDetection = None
    SentimentAnalyzer = None
    FibonacciCalculator = None
    IchimokuAnalyzer = None
    VolumeAnalyzer = None
    DivergenceDetector = None

# Import Phase 3 Data Integration modules
try:
    from ..data_integration import (
        RealtimeDataCollector,
        DataValidator,
        CacheManager,
        MultiSourceAggregator
    )
    DATA_INTEGRATION_AVAILABLE = True
except ImportError as e:
    print(f"Warning: Could not import Data Integration modules: {e}")
    RealtimeDataCollector = None
    DataValidator = None
    CacheManager = None
    MultiSourceAggregator = None
    DATA_INTEGRATION_AVAILABLE = False

class MyToolInput(BaseModel):
    """Input schema for MyCustomTool."""
    argument: str = Field(..., description="M√£ c·ªï phi·∫øu.")

class FundDataTool(BaseTool):
    name: str = "C√¥ng c·ª• tra c·ª©u d·ªØ li·ªáu c·ªï phi·∫øu ph·ª•c v·ª• ph√¢n t√≠ch c∆° b·∫£n."
    description: str = "C√¥ng c·ª• tra c·ª©u d·ªØ li·ªáu c·ªï phi·∫øu ph·ª•c v·ª• ph√¢n t√≠ch c∆° b·∫£n, cung c·∫•p c√°c ch·ªâ s·ªë t√†i ch√≠nh nh∆∞ P/E, P/B, ROE, ROA, EPS, D/E, bi√™n l·ª£i nhu·∫≠n v√† EV/EBITDA."
    args_schema: Type[BaseModel] = MyToolInput

    def _run(self, argument: str) -> str:
        try:
            # Use real data with better error handling and caching
            import time
            import random
            
            # Add random delay to avoid rate limiting
            time.sleep(random.uniform(1, 3))
            
            # Try multiple sources with proper error handling
            sources = ["VCI", "DNSE", "SSI"]
            stock = None
            company = None
            
            for source in sources:
                try:
                    print(f"Trying {source} for {argument}...")
                    stock = Vnstock().stock(symbol=argument, source=source)
                    company = Vnstock().stock(symbol=argument, source=source).company
                    print(f"Successfully got data from {source}")
                    break
                except Exception as e:
                    print(f"Source {source} failed: {str(e)[:100]}...")
                    continue
            
            if stock is None:
                raise Exception("All data sources failed")
                
            financial_ratios = stock.finance.ratio(period="quarter")
            income_df = stock.finance.income_statement(period="quarter")

            # Get company full name & industry with error handling
            try:
                profile_data = company.profile().get("company_name")
                full_name = profile_data.iloc[0] if not profile_data.empty else f"Company {argument}"
            except (IndexError, AttributeError):
                full_name = f"Company {argument}"
            
            try:
                overview_data = company.overview().get("industry")
                industry = overview_data.iloc[0] if not overview_data.empty else "Unknown"
            except (IndexError, AttributeError):
                industry = "Unknown"

            # Get data from the latest row of DataFrame for financial ratios with error handling
            if financial_ratios.empty:
                return f"Kh√¥ng c√≥ d·ªØ li·ªáu t√†i ch√≠nh cho c·ªï phi·∫øu {argument}"
            
            latest_ratios = financial_ratios.iloc[0]

            # Get last 4 quarters of income statement with error handling
            if income_df.empty:
                quarterly_trends = ["Kh√¥ng c√≥ d·ªØ li·ªáu b√°o c√°o thu nh·∫≠p"]
            else:
                last_4_quarters = income_df.head(4)
            
            # Extract financial ratios data - handle both TCBS and VCI formats
            try:
                # Try VCI format first (multi-level columns)
                pe_ratio = latest_ratios.get(('Ch·ªâ ti√™u ƒë·ªãnh gi√°', 'P/E'), "N/A")
                pb_ratio = latest_ratios.get(('Ch·ªâ ti√™u ƒë·ªãnh gi√°', 'P/B'), "N/A")
                roe = latest_ratios.get(('Ch·ªâ ti√™u kh·∫£ nƒÉng sinh l·ª£i', 'ROE (%)'), "N/A")
                roa = latest_ratios.get(('Ch·ªâ ti√™u kh·∫£ nƒÉng sinh l·ª£i', 'ROA (%)'), "N/A")
                eps = latest_ratios.get(('Ch·ªâ ti√™u ƒë·ªãnh gi√°', 'EPS (VND)'), "N/A")
                de = latest_ratios.get(('Ch·ªâ ti√™u c∆° c·∫•u ngu·ªìn v·ªën', 'Debt/Equity'), "N/A")
                profit_margin = latest_ratios.get(('Ch·ªâ ti√™u kh·∫£ nƒÉng sinh l·ª£i', 'Gross Profit Margin (%)'), "N/A")
                evebitda = latest_ratios.get(('Ch·ªâ ti√™u ƒë·ªãnh gi√°', 'EV/EBITDA'), "N/A")
            except:
                # Fallback to TCBS format
                pe_ratio = latest_ratios.get("price_to_earning", "N/A")
                pb_ratio = latest_ratios.get("price_to_book", "N/A")
                roe = latest_ratios.get("roe", "N/A")
                roa = latest_ratios.get("roa", "N/A")
                eps = latest_ratios.get("earning_per_share", "N/A")
                de = latest_ratios.get("debt_on_equity", "N/A")
                profit_margin = latest_ratios.get("gross_profit_margin", "N/A")
                evebitda = latest_ratios.get("value_before_ebitda", "N/A")

                        # Format quarterly income data only if we have data
            if 'last_4_quarters' in locals() and not last_4_quarters.empty:
                quarterly_trends = []
                for i, (_, quarter) in enumerate(last_4_quarters.iterrows()):
                    try:
                        # Detect and normalize units
                        # Revenue
                        revenue = quarter.get("Revenue (Bn. VND)", None)
                        if isinstance(revenue, (int, float)):
                            revenue_bn = revenue if revenue < 1e7 else revenue / 1e9
                            revenue_str = f"{revenue_bn:,.0f} t·ªâ ƒë·ªìng"
                        else:
                            revenue_str = "N/A"
                        # Gross Profit
                        gross_profit = quarter.get("Gross Profit", None)
                        if isinstance(gross_profit, (int, float)):
                            # Assume VND
                            gp_bn = gross_profit / 1e9 if gross_profit >= 1e7 else gross_profit
                            gross_profit_str = f"{gp_bn:,.0f} t·ªâ ƒë·ªìng" if gross_profit >= 1e7 else f"{gp_bn:,.0f} VND"
                        else:
                            gross_profit_str = "N/A"
                        # Net Profit For the Year
                        post_tax_profit = quarter.get("Net Profit For the Year", None)
                        if isinstance(post_tax_profit, (int, float)):
                            npty_bn = post_tax_profit / 1e9 if post_tax_profit >= 1e7 else post_tax_profit
                            post_tax_profit_str = f"{npty_bn:,.0f} t·ªâ ƒë·ªìng" if post_tax_profit >= 1e7 else f"{npty_bn:,.0f} VND"
                        else:
                            post_tax_profit_str = "N/A"

                        quarter_info = f"""
                        Qu√Ω T - {i + 1}:
                        - Doanh thu thu·∫ßn: {revenue_str}
                        - L·ª£i nhu·∫≠n g·ªôp: {gross_profit_str}
                        - L·ª£i nhu·∫≠n sau thu·∫ø: {post_tax_profit_str}
                        """
                        quarterly_trends.append(quarter_info)
                    except Exception:
                        quarterly_trends.append(f"Qu√Ω T - {i + 1}: L·ªói d·ªØ li·ªáu")
            else:
                quarterly_trends = ["Kh√¥ng c√≥ d·ªØ li·ªáu b√°o c√°o thu nh·∫≠p"]
            
            return f"""M√£ c·ªï phi·∫øu: {argument}
            T√™n c√¥ng ty: {full_name}
            Ng√†nh: {industry}
            Ng√†y ph√¢n t√≠ch: {datetime.now().strftime('%Y-%m-%d')}
            
            T·ª∑ l·ªá P/E: {pe_ratio}
            T·ª∑ l·ªá P/B: {pb_ratio}
            T·ª∑ l·ªá ROE: {roe}
            T·ª∑ l·ªá ROA: {roa}
            Bi√™n l·ª£i nhu·∫≠n: {profit_margin}
            L·ª£i nhu·∫≠n tr√™n m·ªói c·ªï phi·∫øu EPS (VND): {eps}
            H·ªá s·ªë n·ª£ tr√™n v·ªën ch·ªß s·ªü h·ªØu D/E: {de}
            T·ª∑ l·ªá EV/EBITDA: {evebitda}

            XU H∆Ø·ªöNG 4 QU√ù G·∫¶N NH·∫§T:
            {"".join(quarterly_trends)}
            """
        except Exception as e:
            return f"L·ªói khi l·∫•y d·ªØ li·ªáu: {e}"
        
class TechDataTool(BaseTool):
    name: str = "C√¥ng c·ª• tra c·ª©u d·ªØ li·ªáu c·ªï phi·∫øu ph·ª•c v·ª• ph√¢n t√≠ch kƒ© thu·∫≠t."
    description: str = "C√¥ng c·ª• tra c·ª©u d·ªØ li·ªáu c·ªï phi·∫øu ph·ª•c v·ª• ph√¢n t√≠ch kƒ© thu·∫≠t, cung c·∫•p c√°c ch·ªâ s·ªë nh∆∞ SMA, EMA, RSI, MACD, Bollinger Bands, v√† v√πng h·ªó tr·ª£/kh√°ng c·ª±."
    args_schema: Type[BaseModel] = MyToolInput

    def _run(self, argument: str) -> str:
        try:
            # Use real data with better error handling and caching
            import time
            import random
            
            # Add random delay to avoid rate limiting
            time.sleep(random.uniform(1, 3))
            
            # Try multiple sources with proper error handling
            sources = ["VCI", "DNSE", "SSI"]
            stock = None
            company = None
            
            for source in sources:
                try:
                    print(f"Trying {source} for {argument}...")
                    stock = Vnstock().stock(symbol=argument, source=source)
                    company = Vnstock().stock(symbol=argument, source=source).company
                    print(f"Successfully got data from {source}")
                    break
                except Exception as e:
                    print(f"Source {source} failed: {str(e)[:100]}...")
                    continue
            
            if stock is None:
                raise Exception("All data sources failed")

            # Get company full name & industry with error handling
            try:
                profile_data = company.profile().get("company_name")
                full_name = profile_data.iloc[0] if not profile_data.empty else f"Company {argument}"
            except (IndexError, AttributeError):
                full_name = f"Company {argument}"
            
            try:
                overview_data = company.overview().get("industry")
                industry = overview_data.iloc[0] if not overview_data.empty else "Unknown"
            except (IndexError, AttributeError):
                industry = "Unknown"
            
            # Phase 3: Initialize data validation if available
            data_validator = None
            if DATA_INTEGRATION_AVAILABLE and DataValidator:
                data_validator = DataValidator()
            
            # Get price data for the last 200 days
            end_date = datetime.now()
            start_date = end_date - timedelta(days=200)
            price_data = stock.quote.history(
                start=start_date.strftime("%Y-%m-%d"),
                end=end_date.strftime("%Y-%m-%d"),
                interval="1D"  # Daily data
            )
            
            if price_data.empty:
                return f"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu l·ªãch s·ª≠ cho c·ªï phi·∫øu {argument}"
            
            # Calculate technical indicators
            tech_data = self._calculate_indicators(price_data)
            
            # Identify support and resistance levels
            support_resistance = self._find_support_resistance(price_data)
            
            # Get recent price and volume data with error handling
            if len(price_data) == 0:
                return f"Kh√¥ng c√≥ d·ªØ li·ªáu gi√° cho c·ªï phi·∫øu {argument}"
            
            current_price = price_data['close'].iloc[-1]
            recent_prices = price_data['close'].iloc[-5:-1] if len(price_data) >= 5 else price_data['close']
            current_volume = price_data['volume'].iloc[-1]
            recent_volumes = price_data['volume'].iloc[-5:-1] if len(price_data) >= 5 else price_data['volume']
            
            # Format result
            latest_indicators = tech_data.iloc[-1]
            
            result = f"""M√£ c·ªï phi·∫øu: {argument}
            T√™n c√¥ng ty: {full_name}
            Ng√†nh: {industry}
            Ng√†y ph√¢n t√≠ch: {datetime.now().strftime('%Y-%m-%d')}
            Gi√° hi·ªán t·∫°i: {(current_price*1000):,.0f} VND
            Kh·ªëi l∆∞·ª£ng giao d·ªãch: {current_volume:,.0f} cp

            GI√Å ƒê√ìNG C·ª¨A G·∫¶N NH·∫§T:
            - T-1: {(recent_prices.iloc[-1]*1000):,.0f} VND (KL: {recent_volumes.iloc[-1]:,.0f} cp)
            - T-2: {(recent_prices.iloc[-2]*1000):,.0f} VND (KL: {recent_volumes.iloc[-2]:,.0f} cp)
            - T-3: {(recent_prices.iloc[-3]*1000):,.0f} VND (KL: {recent_volumes.iloc[-3]:,.0f} cp)
            - T-4: {(recent_prices.iloc[-4]*1000):,.0f} VND (KL: {recent_volumes.iloc[-4]:,.0f} cp)
            
            CH·ªà S·ªê K·ª∏ THU·∫¨T:
            - SMA (20): {(latest_indicators['SMA_20']*1000):,.0f}
            - SMA (50): {(latest_indicators['SMA_50']*1000):,.0f}
            - SMA (200): {(latest_indicators['SMA_200']*1000):,.0f}
            - EMA (12): {(latest_indicators['EMA_12']*1000):,.0f}
            - EMA (26): {(latest_indicators['EMA_26']*1000):,.0f}
            
            - RSI (14): {latest_indicators['RSI_14']:.2f}
            - MACD: {latest_indicators['MACD']:.2f}
            - MACD Signal: {latest_indicators['MACD_Signal']:.2f}
            - MACD Histogram: {latest_indicators['MACD_Hist']:.2f}
            
            - Bollinger Upper: {(latest_indicators['BB_Upper']*1000):,.0f}
            - Bollinger Middle: {(latest_indicators['BB_Middle']*1000):,.0f}
            - Bollinger Lower: {(latest_indicators['BB_Lower']*1000):,.0f}

            CH·ªà S·ªê KH·ªêI L∆Ø·ª¢NG:
            - Kh·ªëi l∆∞·ª£ng hi·ªán t·∫°i: {current_volume:,.0f} cp
            - Trung b√¨nh 10 phi√™n: {latest_indicators['Volume_SMA_10']:,.0f} cp
            - Trung b√¨nh 20 phi√™n: {latest_indicators['Volume_SMA_20']:,.0f} cp
            - Trung b√¨nh 50 phi√™n: {latest_indicators['Volume_SMA_50']:,.0f} cp
            - T·ª∑ l·ªá Kh·ªëi l∆∞·ª£ng / Trung b√¨nh 20: {latest_indicators['Volume_Ratio_20']:.2f}
            - On-Balance Volume (OBV): {latest_indicators['OBV']:,.0f}
            
            V√ôNG H·ªñ TR·ª¢ V√Ä KH√ÅNG C·ª∞:
            {support_resistance}
            
            NH·∫¨N ƒê·ªäNH K·ª∏ THU·∫¨T:
            {self._get_technical_analysis(latest_indicators, current_price, support_resistance)}
            
            PH√ÇN T√çCH MACHINE LEARNING:
            {self._run_ml_analysis(tech_data)}
            
            PH√ÇN T√çCH K·ª∏ THU·∫¨T N√ÇNG CAO:
            {self._run_advanced_technical_analysis(tech_data)}
            
            {self._get_data_quality_assessment(data_validator, current_price, current_volume, latest_indicators)}
            """
            return result
            
        except Exception as e:
            return f"L·ªói khi l·∫•y d·ªØ li·ªáu k·ªπ thu·∫≠t: {e}"
    
    def _calculate_indicators(self, df):
        """Calculate various technical indicators."""
        # Make a copy to avoid modifying original data
        data = df.copy()
        
        # Simple Moving Averages
        data['SMA_20'] = data['close'].rolling(window=20).mean()
        data['SMA_50'] = data['close'].rolling(window=50).mean()
        data['SMA_200'] = data['close'].rolling(window=200).mean()
        
        # Exponential Moving Averages
        data['EMA_12'] = data['close'].ewm(span=12, adjust=False).mean()
        data['EMA_26'] = data['close'].ewm(span=26, adjust=False).mean()
        
        # MACD
        data['MACD'] = data['EMA_12'] - data['EMA_26']
        data['MACD_Signal'] = data['MACD'].ewm(span=9, adjust=False).mean()
        data['MACD_Hist'] = data['MACD'] - data['MACD_Signal']
        
        # RSI
        delta = data['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        
        # Avoid division by zero
        rs = gain / loss.replace(0, np.nan)
        data['RSI_14'] = 100 - (100 / (1 + rs))
        data['RSI_14'] = data['RSI_14'].fillna(50)  # Fill NaN values with neutral RSI
        
        # Bollinger Bands
        data['BB_Middle'] = data['close'].rolling(window=20).mean()
        std_dev = data['close'].rolling(window=20).std()
        data['BB_Upper'] = data['BB_Middle'] + (std_dev * 2)
        data['BB_Lower'] = data['BB_Middle'] - (std_dev * 2)

        # Calculate volume moving averages
        data['Volume_SMA_10'] = data['volume'].rolling(window=10).mean()
        data['Volume_SMA_20'] = data['volume'].rolling(window=20).mean()
        data['Volume_SMA_50'] = data['volume'].rolling(window=50).mean()
        
        # Calculate volume ratio compared to average
        data['Volume_Ratio_10'] = data['volume'] / data['Volume_SMA_10']
        data['Volume_Ratio_20'] = data['volume'] / data['Volume_SMA_20']
        
        # On-Balance Volume (OBV)
        data['OBV'] = 0
        data.loc[0, 'OBV'] = data.loc[0, 'volume']
        for i in range(1, len(data)):
            if data.loc[i, 'close'] > data.loc[i-1, 'close']:
                data.loc[i, 'OBV'] = data.loc[i-1, 'OBV'] + data.loc[i, 'volume']
            elif data.loc[i, 'close'] < data.loc[i-1, 'close']:
                data.loc[i, 'OBV'] = data.loc[i-1, 'OBV'] - data.loc[i, 'volume']
            else:
                data.loc[i, 'OBV'] = data.loc[i-1, 'OBV']
        
        return data
    
    def _find_support_resistance(self, df, window=10, threshold=0.03):
        """Find support and resistance levels."""
        data = df.copy()
        
        # Find potential pivot points
        data['local_max'] = data['high'].rolling(window=window, center=True).apply(
            lambda x: x.iloc[len(x)//2] == max(x), raw=False
        )
        data['local_min'] = data['low'].rolling(window=window, center=True).apply(
            lambda x: x.iloc[len(x)//2] == min(x), raw=False
        )
        
        # Get pivot high/low points
        resistance_levels = data[data['local_max'] == 1]['high'].values
        support_levels = data[data['local_min'] == 1]['low'].values
        
        # Group close resistance/support levels
        if len(data) == 0:
            return {"support_levels": [], "resistance_levels": []}
        
        current_price = data['close'].iloc[-1]
        
        # Function to cluster price levels
        def cluster_levels(levels, threshold_pct):
            if len(levels) == 0:
                return []
                
            levels = sorted(levels)
            clusters = [[levels[0]]]
            
            for level in levels[1:]:
                last_cluster = clusters[-1]
                last_value = last_cluster[-1]
                
                # If this level is within threshold% of the last value, add to the same cluster
                if abs((level - last_value) / last_value) < threshold_pct:
                    last_cluster.append(level)
                else:
                    clusters.append([level])
            
            # Calculate average for each cluster
            return [np.mean(cluster) for cluster in clusters]
        
        # Cluster and filter resistance levels
        resistance_levels = cluster_levels(resistance_levels, threshold)
        resistance_levels = [r for r in resistance_levels if r > current_price]
        resistance_levels = sorted(resistance_levels)[:3]  # Get nearest 3 levels
        
        # Cluster and filter support levels
        support_levels = cluster_levels(support_levels, threshold)
        support_levels = [s for s in support_levels if s < current_price]
        support_levels = sorted(support_levels, reverse=True)[:3]  # Get nearest 3 levels
        
        # Format result
        result = "V√πng kh√°ng c·ª±:\n"
        for i, level in enumerate(resistance_levels, 1):
            result += f"- R{i}: {level*1000:,.0f} VND\n"
        
        result += "\nV√πng h·ªó tr·ª£:\n"
        for i, level in enumerate(support_levels, 1):
            result += f"- S{i}: {level*1000:,.0f} VND\n"
            
        return result
    
    def _get_technical_analysis(self, indicators, current_price, support_resistance):
        """Generate technical analysis text based on indicators."""
        analysis = []
        
        # Trend analysis based on SMAs
        if current_price > indicators['SMA_200'] and indicators['SMA_50'] > indicators['SMA_200']:
            analysis.append("- Xu h∆∞·ªõng d√†i h·∫°n: TƒÇNG (Gi√° tr√™n SMA 200, SMA 50 tr√™n SMA 200)")
        elif current_price < indicators['SMA_200'] and indicators['SMA_50'] < indicators['SMA_200']:
            analysis.append("- Xu h∆∞·ªõng d√†i h·∫°n: GI·∫¢M (Gi√° d∆∞·ªõi SMA 200, SMA 50 d∆∞·ªõi SMA 200)")
        else:
            analysis.append("- Xu h∆∞·ªõng d√†i h·∫°n: TRUNG L·∫¨P (T√≠n hi·ªáu tr√°i chi·ªÅu gi·ªØa c√°c SMA)")
        
        # Short-term trend
        if current_price > indicators['SMA_20'] and indicators['SMA_20'] > indicators['SMA_50']:
            analysis.append("- Xu h∆∞·ªõng ng·∫Øn h·∫°n: TƒÇNG (Gi√° tr√™n SMA 20, SMA 20 tr√™n SMA 50)")
        elif current_price < indicators['SMA_20'] and indicators['SMA_20'] < indicators['SMA_50']:
            analysis.append("- Xu h∆∞·ªõng ng·∫Øn h·∫°n: GI·∫¢M (Gi√° d∆∞·ªõi SMA 20, SMA 20 d∆∞·ªõi SMA 50)")
        else:
            analysis.append("- Xu h∆∞·ªõng ng·∫Øn h·∫°n: TRUNG L·∫¨P (T√≠n hi·ªáu tr√°i chi·ªÅu gi·ªØa SMA ng·∫Øn h·∫°n)")
        
        # RSI analysis
        if indicators['RSI_14'] > 70:
            analysis.append("- RSI: QU√Å MUA (RSI > 70), c√≥ kh·∫£ nƒÉng ƒëi·ªÅu ch·ªânh gi·∫£m")
        elif indicators['RSI_14'] < 30:
            analysis.append("- RSI: QU√Å B√ÅN (RSI < 30), c√≥ kh·∫£ nƒÉng h·ªìi ph·ª•c")
        else:
            analysis.append(f"- RSI: TRUNG T√çNH ({indicators['RSI_14']:.2f})")
        
        # MACD analysis
        if indicators['MACD'] > indicators['MACD_Signal']:
            analysis.append("- MACD: T√çCH C·ª∞C (MACD tr√™n Signal Line)")
        else:
            analysis.append("- MACD: TI√äU C·ª∞C (MACD d∆∞·ªõi Signal Line)")
        
        # Bollinger Bands analysis
        if current_price > indicators['BB_Upper']:
            analysis.append("- Bollinger Bands: QU√Å MUA (Gi√° tr√™n d·∫£i tr√™n BB)")
        elif current_price < indicators['BB_Lower']:
            analysis.append("- Bollinger Bands: QU√Å B√ÅN (Gi√° d∆∞·ªõi d·∫£i d∆∞·ªõi BB)")
        else:
            position = (current_price - indicators['BB_Lower']) / (indicators['BB_Upper'] - indicators['BB_Lower'])
            if position > 0.8:
                analysis.append("- Bollinger Bands: G·∫¶N V√ôNG QU√Å MUA (Gi√° g·∫ßn d·∫£i tr√™n BB)")
            elif position < 0.2:
                analysis.append("- Bollinger Bands: G·∫¶N V√ôNG QU√Å B√ÅN (Gi√° g·∫ßn d·∫£i d∆∞·ªõi BB)")
            else:
                analysis.append("- Bollinger Bands: TRUNG T√çNH (Gi√° trong kho·∫£ng gi·ªØa d·∫£i BB)")
        
        # Volume ratio analysis
        volume_ratio_20 = indicators['Volume_Ratio_20']
        if volume_ratio_20 > 2.0:
            analysis.append("- Kh·ªëi l∆∞·ª£ng: R·∫§T CAO (>200% trung b√¨nh 20 phi√™n)")
        elif volume_ratio_20 > 1.5:
            analysis.append("- Kh·ªëi l∆∞·ª£ng: CAO (150-200% trung b√¨nh 20 phi√™n)")
        elif volume_ratio_20 < 0.5:
            analysis.append("- Kh·ªëi l∆∞·ª£ng: TH·∫§P (<50% trung b√¨nh 20 phi√™n)")
        else:
            analysis.append("- Kh·ªëi l∆∞·ª£ng: B√åNH TH∆Ø·ªúNG (50-150% trung b√¨nh 20 phi√™n)")

        # Volume trend analysis
        if (indicators['Volume_SMA_10'] > indicators['Volume_SMA_20'] and 
            indicators['Volume_SMA_20'] > indicators['Volume_SMA_50']):
            analysis.append("- Xu h∆∞·ªõng kh·ªëi l∆∞·ª£ng: TƒÇNG (SMA 10 > SMA 20 > SMA 50)")
        elif (indicators['Volume_SMA_10'] < indicators['Volume_SMA_20'] and 
            indicators['Volume_SMA_20'] < indicators['Volume_SMA_50']):
            analysis.append("- Xu h∆∞·ªõng kh·ªëi l∆∞·ª£ng: GI·∫¢M (SMA 10 < SMA 20 < SMA 50)")
        else:
            analysis.append("- Xu h∆∞·ªõng kh·ªëi l∆∞·ª£ng: TRUNG L·∫¨P")

        # OBV trend analysis
        current_volume = indicators['volume']
        if current_volume > indicators['Volume_SMA_20'] * 1.5:
            if current_price > indicators['SMA_20']:
                analysis.append("- T√≠n hi·ªáu kh·ªëi l∆∞·ª£ng: T√çCH C·ª∞C (Kh·ªëi l∆∞·ª£ng cao k√®m gi√° tƒÉng)")
            else:
                analysis.append("- T√≠n hi·ªáu kh·ªëi l∆∞·ª£ng: TI√äU C·ª∞C (Kh·ªëi l∆∞·ª£ng cao k√®m gi√° gi·∫£m)")

        return "\n".join(analysis)
    
    def _run_ml_analysis(self, data_with_indicators):
        """Run ML analysis on the data."""
        try:
            if not all([PatternRecognition, AnomalyDetection]):
                return "ML modules kh√¥ng kh·∫£ d·ª•ng"
            
            prices = data_with_indicators['close'].tolist()
            volumes = data_with_indicators['volume'].tolist()
            
            ml_results = []
            
            # Pattern Recognition
            pattern_analyzer = PatternRecognition()
            patterns = pattern_analyzer.analyze_patterns(prices, volumes)
            if patterns:
                pattern_summary = pattern_analyzer.get_pattern_summary(patterns)
                ml_results.append(f"üìä PATTERN RECOGNITION:")
                ml_results.append(f"- Ph√°t hi·ªán {pattern_summary['total_patterns']} patterns")
                ml_results.append(f"- T√≠n hi·ªáu ch√≠nh: {pattern_summary['primary_signal']}")
                ml_results.append(f"- Khuy·∫øn ngh·ªã: {pattern_summary['recommendation']}")
            
            # Anomaly Detection
            anomaly_detector = AnomalyDetection()
            anomaly_analysis = anomaly_detector.comprehensive_anomaly_analysis(prices, volumes)
            if anomaly_analysis.get('total_anomalies', 0) > 0:
                ml_results.append(f"üö® ANOMALY DETECTION:")
                ml_results.append(f"- Ph√°t hi·ªán {anomaly_analysis['total_anomalies']} b·∫•t th∆∞·ªùng")
                ml_results.append(f"- M·ª©c ƒë·ªô r·ªßi ro: {anomaly_analysis['risk_level']}")
                ml_results.append(f"- T√≥m t·∫Øt: {anomaly_analysis['summary']}")
            
            return "\n".join(ml_results) if ml_results else "Kh√¥ng ph√°t hi·ªán pattern ho·∫∑c anomaly ƒë√°ng k·ªÉ"
            
        except Exception as e:
            return f"L·ªói ML analysis: {str(e)}"
    
    def _run_advanced_technical_analysis(self, data_with_indicators):
        """Run advanced technical analysis."""
        try:
            if not all([FibonacciCalculator, IchimokuAnalyzer, VolumeAnalyzer, DivergenceDetector]):
                return "Advanced technical modules kh√¥ng kh·∫£ d·ª•ng"
            
            prices = data_with_indicators['close'].tolist()
            highs = data_with_indicators['high'].tolist()
            lows = data_with_indicators['low'].tolist()
            volumes = data_with_indicators['volume'].tolist()
            
            advanced_results = []
            
            # Fibonacci Analysis
            fib_calc = FibonacciCalculator()
            fib_summary = fib_calc.get_fibonacci_summary(prices)
            if 'error' not in fib_summary:
                advanced_results.append(f"üìê FIBONACCI ANALYSIS:")
                advanced_results.append(f"- Xu h∆∞·ªõng: {fib_summary['trend_direction']}")
                advanced_results.append(f"- Swing High: {fib_summary['swing_high']:,.0f}")
                advanced_results.append(f"- Swing Low: {fib_summary['swing_low']:,.0f}")
                if fib_summary.get('price_analysis', {}).get('recommendation'):
                    advanced_results.append(f"- Khuy·∫øn ngh·ªã: {fib_summary['price_analysis']['recommendation']}")
            
            # Ichimoku Analysis
            ichimoku_analyzer = IchimokuAnalyzer()
            ichimoku_summary = ichimoku_analyzer.get_ichimoku_summary(highs, lows, prices)
            if 'error' not in ichimoku_summary:
                trading_signal = ichimoku_summary['trading_signal']
                advanced_results.append(f"‚òÅÔ∏è ICHIMOKU ANALYSIS:")
                advanced_results.append(f"- T√≠n hi·ªáu: {trading_signal['signal']} ({trading_signal['strength']})")
                advanced_results.append(f"- ƒê·ªô tin c·∫≠y: {trading_signal['confidence']:.1%}")
                advanced_results.append(f"- M√¥ t·∫£: {trading_signal['description']}")
            
            # Volume Profile Analysis
            volume_analyzer = VolumeAnalyzer()
            volume_summary = volume_analyzer.get_volume_summary(prices, volumes, highs, lows)
            if 'error' not in volume_summary:
                advanced_results.append(f"üìä VOLUME PROFILE:")
                advanced_results.append(f"- V·ªã tr√≠ vs VWAP: {volume_summary['price_vs_vwap']}")
                advanced_results.append(f"- V·ªã tr√≠ vs Value Area: {volume_summary['volume_profile_position']}")
                volume_trend = volume_summary['volume_trend']
                advanced_results.append(f"- Xu h∆∞·ªõng volume: {volume_trend['volume_assessment']}")
            
            # Divergence Analysis
            divergence_detector = DivergenceDetector()
            divergence_analysis = divergence_detector.get_comprehensive_divergence_analysis(prices, volumes, highs, lows)
            if divergence_analysis.get('total_divergences', 0) > 0:
                advanced_results.append(f"üîÑ DIVERGENCE ANALYSIS:")
                advanced_results.append(f"- T·ªïng divergences: {divergence_analysis['total_divergences']}")
                advanced_results.append(f"- T√≠n hi·ªáu t·ªïng th·ªÉ: {divergence_analysis['overall_signal']}")
                advanced_results.append(f"- T√≥m t·∫Øt: {divergence_analysis['summary']}")
            
            return "\n".join(advanced_results) if advanced_results else "Kh√¥ng c√≥ t√≠n hi·ªáu advanced technical ƒë√°ng k·ªÉ"
            
        except Exception as e:
            return f"L·ªói advanced technical analysis: {str(e)}"
    
    def _get_data_quality_assessment(self, data_validator, current_price, current_volume, latest_indicators):
        """Get data quality assessment for Phase 3."""
        try:
            if not data_validator or not DATA_INTEGRATION_AVAILABLE:
                return ""
            
            # Prepare data for validation
            price_data = {
                'price': current_price,
                'volume': current_volume,
                'change_percent': latest_indicators.get('Price_Change_Pct', 0),
                'open': latest_indicators.get('Open', current_price),
                'high': latest_indicators.get('High', current_price),
                'low': latest_indicators.get('Low', current_price),
                'close': current_price
            }
            
            # Validate price data
            validation_results = data_validator.validate_price_data(price_data)
            
            if not validation_results:
                return """
üìä ƒê√ÅNH GI√Å CH·∫§T L∆Ø·ª¢NG D·ªÆ LI·ªÜU (PHASE 3):
‚úÖ D·ªØ li·ªáu ƒë√£ qua ki·ªÉm tra - Kh√¥ng ph√°t hi·ªán v·∫•n ƒë·ªÅ
‚Ä¢ ƒê·ªô tin c·∫≠y: CAO
‚Ä¢ Tr·∫°ng th√°i: S·∫¥N S√ÄNG S·ª¨ D·ª§NG
"""
            
            # Analyze validation results
            errors = [r for r in validation_results if r.level.value == 'error']
            warnings = [r for r in validation_results if r.level.value == 'warning']
            critical = [r for r in validation_results if r.level.value == 'critical']
            
            quality_assessment = ["üìä ƒê√ÅNH GI√Å CH·∫§T L∆Ø·ª¢NG D·ªÆ LI·ªÜU (PHASE 3):"]
            
            if critical:
                quality_assessment.append("üö® V·∫§N ƒê·ªÄ NGHI√äM TR·ªåNG:")
                for issue in critical:
                    quality_assessment.append(f"  ‚Ä¢ {issue.message}")
                quality_assessment.append("‚Ä¢ Tr·∫°ng th√°i: C·∫¶N KI·ªÇM TRA NGAY")
            
            elif errors:
                quality_assessment.append("‚ö†Ô∏è L·ªñI D·ªÆ LI·ªÜU:")
                for error in errors:
                    quality_assessment.append(f"  ‚Ä¢ {error.message}")
                quality_assessment.append("‚Ä¢ Tr·∫°ng th√°i: C·∫¶N TH·∫¨N TR·ªåNG")
            
            elif warnings:
                quality_assessment.append("üí° C·∫¢NH B√ÅO:")
                for warning in warnings:
                    quality_assessment.append(f"  ‚Ä¢ {warning.message}")
                quality_assessment.append("‚Ä¢ Tr·∫°ng th√°i: CH·∫§P NH·∫¨N ƒê∆Ø·ª¢C")
            
            # Overall assessment
            total_issues = len(critical) + len(errors) + len(warnings)
            if total_issues == 0:
                quality_assessment.append("‚Ä¢ ƒê·ªô tin c·∫≠y: CAO")
            elif len(critical) > 0 or len(errors) > 2:
                quality_assessment.append("‚Ä¢ ƒê·ªô tin c·∫≠y: TH·∫§P")
            else:
                quality_assessment.append("‚Ä¢ ƒê·ªô tin c·∫≠y: TRUNG B√åNH")
            
            quality_assessment.append(f"‚Ä¢ T·ªïng v·∫•n ƒë·ªÅ ph√°t hi·ªán: {total_issues}")
            quality_assessment.append("‚Ä¢ H·ªá th·ªëng: Enhanced Data Validation v0.6.0")
            
            return "\n".join(quality_assessment)
            
        except Exception as e:
            return f"\nüìä ƒê√ÅNH GI√Å CH·∫§T L∆Ø·ª¢NG D·ªÆ LI·ªÜU: L·ªói ki·ªÉm tra - {str(e)}"

class SentimentAnalysisTool(BaseTool):
    name: str = "C√¥ng c·ª• ph√¢n t√≠ch sentiment t·ª´ tin t·ª©c v√† social media."
    description: str = "C√¥ng c·ª• ph√¢n t√≠ch sentiment t·ª´ tin t·ª©c, b√°o c√°o, v√† social media ƒë·ªÉ ƒë√°nh gi√° t√¢m l√Ω th·ªã tr∆∞·ªùng ƒë·ªëi v·ªõi c·ªï phi·∫øu."
    args_schema: Type[BaseModel] = MyToolInput

    def _run(self, argument: str) -> str:
        try:
            if not SentimentAnalyzer:
                return "Sentiment Analysis module kh√¥ng kh·∫£ d·ª•ng"
            
            # Initialize sentiment analyzer
            sentiment_analyzer = SentimentAnalyzer()
            
            # Sample news articles (in real implementation, this would fetch from news APIs)
            sample_news = [
                {
                    "title": f"C·ªï phi·∫øu {argument.upper()} c√≥ tri·ªÉn v·ªçng t√≠ch c·ª±c trong qu√Ω t·ªõi",
                    "content": f"C√°c chuy√™n gia d·ª± b√°o {argument.upper()} s·∫Ω c√≥ k·∫øt qu·∫£ kinh doanh kh·∫£ quan nh·ªù tƒÉng tr∆∞·ªüng doanh thu v√† c·∫£i thi·ªán bi√™n l·ª£i nhu·∫≠n.",
                    "source": "VnExpress"
                },
                {
                    "title": f"√Åp l·ª±c b√°n th√°o tr√™n {argument.upper()} do lo ng·∫°i v·ªÅ t√¨nh h√¨nh kinh t·∫ø",
                    "content": f"Nh√† ƒë·∫ßu t∆∞ lo ng·∫°i v·ªÅ t√°c ƒë·ªông c·ªßa l·∫°m ph√°t ƒë·∫øn k·∫øt qu·∫£ kinh doanh c·ªßa {argument.upper()}, g√¢y √°p l·ª±c b√°n m·∫°nh.",
                    "source": "CafeF"
                },
                {
                    "title": f"Khuy·∫øn ngh·ªã mua {argument.upper()} v·ªõi m·ª•c ti√™u gi√° cao h∆°n",
                    "content": f"C√¥ng ty ch·ª©ng kho√°n ABC n√¢ng h·∫°ng {argument.upper()} l√™n MUA v·ªõi m·ª•c ti√™u gi√° tƒÉng 20% so v·ªõi hi·ªán t·∫°i.",
                    "source": "ƒê·∫ßu t∆∞ Ch·ª©ng kho√°n"
                }
            ]
            
            # Analyze sentiment
            sentiment_result = sentiment_analyzer.analyze_news_batch(sample_news)
            
            result = f"""
=== PH√ÇN T√çCH SENTIMENT CHO M√É {argument.upper()} ===

üìä T·ªîNG QUAN SENTIMENT:
- T·ªïng s·ªë b√†i b√°o ph√¢n t√≠ch: {sentiment_result['total_articles']}
- Sentiment trung b√¨nh: {sentiment_result['average_sentiment']:.2f}
- ƒê·ªô tin c·∫≠y trung b√¨nh: {sentiment_result['average_confidence']:.1%}
- Outlook th·ªã tr∆∞·ªùng: {sentiment_result['market_outlook']}

üìà PH√ÇN B·ªê SENTIMENT:
- B√†i b√°o t√≠ch c·ª±c: {sentiment_result['positive_articles']} ({sentiment_result['sentiment_distribution']['positive']:.1%})
- B√†i b√°o ti√™u c·ª±c: {sentiment_result['negative_articles']} ({sentiment_result['sentiment_distribution']['negative']:.1%})
- B√†i b√°o trung t√≠nh: {sentiment_result['neutral_articles']} ({sentiment_result['sentiment_distribution']['neutral']:.1%})

üéØ T√çN HI·ªÜU SENTIMENT:
- T√≠n hi·ªáu bullish: {sentiment_result['bullish_signals']}
- T√≠n hi·ªáu bearish: {sentiment_result['bearish_signals']}

üîë T·ª™ KH√ìA QUAN TR·ªåNG:
{', '.join(sentiment_result['top_key_phrases']) if sentiment_result['top_key_phrases'] else 'Kh√¥ng c√≥ t·ª´ kh√≥a n·ªïi b·∫≠t'}

üí° KHUY·∫æN NGH·ªä:
{sentiment_result['recommendation']}

‚ö†Ô∏è L∆ØU √ù: ƒê√¢y l√† ph√¢n t√≠ch m·∫´u v·ªõi d·ªØ li·ªáu gi·∫£ l·∫≠p. Trong th·ª±c t·∫ø c·∫ßn t√≠ch h·ª£p v·ªõi API tin t·ª©c th·ª±c t·∫ø.
"""
            
            return result
            
        except Exception as e:
            return f"L·ªói khi ph√¢n t√≠ch sentiment cho m√£ {argument}: {str(e)}"
    
# Re-write basic FileReadTool but with utf-8 encoding
class FileReadToolSchema(BaseModel):
    """Input for FileReadTool."""

    file_path: str = Field(..., description="Mandatory file full path to read the file")
    start_line: Optional[int] = Field(1, description="Line number to start reading from (1-indexed)")
    line_count: Optional[int] = Field(None, description="Number of lines to read. If None, reads the entire file")


class FileReadTool(BaseTool):
    """A tool for reading file contents.

    This tool inherits its schema handling from BaseTool to avoid recursive schema
    definition issues. The args_schema is set to FileReadToolSchema which defines
    the required file_path parameter. The schema should not be overridden in the
    constructor as it would break the inheritance chain and cause infinite loops.

    The tool supports two ways of specifying the file path:
    1. At construction time via the file_path parameter
    2. At runtime via the file_path parameter in the tool's input

    Args:
        file_path (Optional[str]): Path to the file to be read. If provided,
            this becomes the default file path for the tool.
        **kwargs: Additional keyword arguments passed to BaseTool.

    Example:
        >>> tool = FileReadTool(file_path="/path/to/file.txt")
        >>> content = tool.run()  # Reads /path/to/file.txt
        >>> content = tool.run(file_path="/path/to/other.txt")  # Reads other.txt
        >>> content = tool.run(file_path="/path/to/file.txt", start_line=100, line_count=50)  # Reads lines 100-149
    """

    name: str = "Read a file's content"
    description: str = "A tool that reads the content of a file. To use this tool, provide a 'file_path' parameter with the path to the file you want to read. Optionally, provide 'start_line' to start reading from a specific line and 'line_count' to limit the number of lines read."
    args_schema: Type[BaseModel] = FileReadToolSchema
    file_path: Optional[str] = None

    def __init__(self, file_path: Optional[str] = None, **kwargs: Any) -> None:
        """Initialize the FileReadTool.

        Args:
            file_path (Optional[str]): Path to the file to be read. If provided,
                this becomes the default file path for the tool.
            **kwargs: Additional keyword arguments passed to BaseTool.
        """
        if file_path is not None:
            kwargs["description"] = (
                f"A tool that reads file content. The default file is {file_path}, but you can provide a different 'file_path' parameter to read another file. You can also specify 'start_line' and 'line_count' to read specific parts of the file."
            )

        super().__init__(**kwargs)
        self.file_path = file_path

    def _run(
        self,
        **kwargs: Any,
    ) -> str:
        file_path = kwargs.get("file_path", self.file_path)
        start_line = kwargs.get("start_line", 1)
        line_count = kwargs.get("line_count", None)

        if file_path is None:
            return (
                "Error: No file path provided. Please provide a file path either in the constructor or as an argument."
            )

        try:
            with open(file_path, "r", encoding="utf-8") as file:
                if start_line == 1 and line_count is None:
                    return file.read()

                start_idx = max(start_line - 1, 0)

                selected_lines = [
                    line
                    for i, line in enumerate(file)
                    if i >= start_idx and (line_count is None or i < start_idx + line_count)
                ]

                if not selected_lines and start_idx > 0:
                    return f"Error: Start line {start_line} exceeds the number of lines in the file."

                return "".join(selected_lines)
        except FileNotFoundError:
            return f"Error: File not found at path: {file_path}"
        except PermissionError:
            return f"Error: Permission denied when trying to read file: {file_path}"
        except Exception as e:
            return f"Error: Failed to read file {file_path}. {str(e)}"